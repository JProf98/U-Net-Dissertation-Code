#Acknowledgements go to Python for microscopists for their U-Net tutorials, this code is a slight adaptation from their original code
#Python for microscopists original code - https://github.com/bnsreenu/python_for_microscopists/blob/master/076-077-078-Unet_nuclei_tutorial.py
#Links to their YouTube series can be seen on their code

"""
@Authour: Jacob Proffitt
"""

import tensorflow as tf
import os
import random
import numpy as np

from tqdm import tqdm 

from skimage.io import imread, imshow
from skimage.transform import resize
import matplotlib.pyplot as plt

seed = 42
np.random.seed = seed

#Input layer, dimensions and number of channels of the image
Width = 256
Height = 256
#As the image is a colour image, the number of channels is 3
Channels = 3

##############################################################################

#TRAINING

TRAIN_PATH = 'Train/'
TEST_PATH = 'Test/'

train_ids = next(os.walk(TRAIN_PATH))[1]
test_ids = next(os.walk(TEST_PATH))[1]

X_train = np.zeros((len(train_ids), Width, Height, Channels), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), Width, Height, Channels), dtype=np.uint8)

#Resizing the training images
print('Resizing training images')
for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   
    path = TRAIN_PATH + id_
    img = imread(path + '/IMG_1/' + id_ + '.tif')[:,:,:Channels]  
    img = resize(img, (Width, Height, Channels), mode='constant', preserve_range=True)
    X_train[n] = img  #Fill empty X_train with values from img    

print('Resizing training images')
for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   
    path = TRAIN_PATH + id_
    img = imread(path + '/IMG_2/' + id_ + '.tif')[:,:,:Channels]  
    img = resize(img, (Width, Height, Channels), mode='constant', preserve_range=True)
    Y_train[n] = img  #Fill empty Y_train with values from img
    
#Resizing the test images
X_test = np.zeros((len(test_ids), Width, Height, Channels), dtype=np.uint8)
sizes_test = []
print('Resizing test images') 
for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):
    path = TEST_PATH + id_
    img = imread(path + '/IMG/' + id_ + '.tif')[:,:,:Channels]
    sizes_test.append([img.shape[0], img.shape[1]])
    img = resize(img, (Width, Height), mode='constant', preserve_range=True)
    X_test[n] = img  

print('Done!')

image_x = random.randint(0, len(train_ids))
imshow(X_train[image_x])
plt.show()
imshow(np.squeeze(Y_train[image_x]))
plt.show()

##############################################################################

#Inputs

inputs = tf.keras.layers.Input((Width, Height, Channels))
#Converting pixel value to floating point values, the convolutional layers and kernel initialiser use floating point values
s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)
#Padding was kept the same so that the input and output images were of the same dimensions

##############################################################################

#Downsampling

#1st Convolutional layer
c1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(s)
#Dropout to prevent overfitting 
c1 = tf.keras.layers.Dropout(0.1)(c1)
c1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c1)
#Pooling layer
p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)


#2nd Convolutional layer
c2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p1)
#Dropout to prevent overfitting 
c2 = tf.keras.layers.Dropout(0.1)(c2)
c2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c2)
#Pooling layer
p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)


#3rd Convolutional layer
c3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p2)
#Dropout to prevent overfitting 
c3 = tf.keras.layers.Dropout(0.2)(c3)
c3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c3)
#Pooling layer
p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)


#4th Convolutional layer
c4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p3)
#Dropout to prevent overfitting 
c4 = tf.keras.layers.Dropout(0.2)(c4)
c4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c4)
#Pooling layer
p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)


#5th Convolutional layer
c5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p4)
#Dropout to prevent overfitting 
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c5)
#Pooling layer
p5 = tf.keras.layers.MaxPooling2D((2,2))(c5)

##############################################################################

#Expansion path


#6th Convolutional layer
#Increasing the resolution of the image
u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides = (2,2), padding = 'same')(c5)
#Adding the layers
u6 = tf.keras.layers.concatenate([u6,c4])
c6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c6)


#7th Convolutional layer
#Increasing the resolution of the image
u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides = (2,2), padding = 'same')(c6)
#Adding the layers
u7 = tf.keras.layers.concatenate([u7,c3])
c7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c7)


#8th Convolutional layer
#Increasing the resolution of the image
u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides = (2,2), padding = 'same')(c7)
#Adding the layers
u8 = tf.keras.layers.concatenate([u8,c2])
c8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
c8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c8)


#9th Convolutional layer
#Increasing the resolution of the image
u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides = (2,2), padding = 'same')(c8)
#Adding the layers
u9 = tf.keras.layers.concatenate([u9,c1])
c9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
c9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c9)

##############################################################################

#Output layer

outputs = tf.keras.layers.Conv2D(3, (1,1), activation = 'softmax')(c9)

##############################################################################

#Solving the model

model = tf.keras.Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])
model.summary()

##############################################################################

#Model fitting

#Modelcheckpoint
checkpointer = tf.keras.callbacks.ModelCheckpoint('Subsurface_model.h5', verbose=1, save_best_only=True)

#Early stopping
callbacks = [
        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),
        tf.keras.callbacks.TensorBoard(log_dir='logs')]

results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks)

##############################################################################

#Checks

idx = random.randint(0, len(X_train))


preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)
preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)
preds_test = model.predict(X_test, verbose=1)

 
preds_train_t = (preds_train > 0.5).astype(np.uint8)
preds_val_t = (preds_val > 0.5).astype(np.uint8)
preds_test_t = (preds_test > 0.5).astype(np.uint8)


#Checking training samples
ix = random.randint(0, len(preds_train_t))
imshow(X_train[ix])
plt.show()
imshow(np.squeeze(Y_train[ix]))
plt.show()
imshow(np.squeeze(preds_train_t[ix]))
plt.show()

#Checking validation samples
ix = random.randint(0, len(preds_val_t))
imshow(X_train[int(X_train.shape[0]*0.9):][ix])
plt.show()
imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))
plt.show()
imshow(np.squeeze(preds_val_t[ix]))
plt.show()
